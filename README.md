# ğŸ“ Admissions Counseling Chatbot

AI-powered chatbot system for university admissions counseling using **LangGraph**, **LangChain**, **Elasticsearch**, and **React**.

**Disclaimer:** This project was designed by a student and is for reference and learning purposes only.


## ğŸ“‹ Features

- âœ… Conversational AI using LangGraph workflow
- âœ… RAG (Retrieval-Augmented Generation) with Elasticsearch
- âœ… Vietnamese language support
- âœ… Hybrid search (BM25 + Vector similarity)
- âœ… Conversation history management
- âœ… Real-time streaming responses
- âœ… User authentication & authorization
- âœ… Modern React UI

## ğŸ—ï¸ Architecture

```
Frontend (React + Vite)
    â†“
Backend (FastAPI + LangGraph)
    â†“
â”œâ”€â”€ Elasticsearch (Document Retrieval)
â”œâ”€â”€ MongoDB (Conversation Storage)
â””â”€â”€ Gemini API (LLM)
```

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **LangChain** - LLM orchestration
- **LangGraph** - Conversational workflow engine
- **Elasticsearch** - Hybrid search engine
- **MongoDB** - NoSQL database
- **Sentence-Transformers** - Vietnamese embeddings

### Frontend
- **React** - UI library
- **Vite** - Build tool
- **Tailwind CSS** - Styling
- **Zustand** - State management

### AI/ML
- **Google Gemini Pro** - Large Language Model
- **Vietnamese SBERT** - Embeddings model

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10+
- Node.js 18+
- Docker & Docker Compose (for MongoDB)
- Elastic Cloud account (or local Elasticsearch)
- Google Gemini API key

### 1. Clone Repository

```bash
git clone <repository-url>
cd Langgragh
```

### 2. Environment Setup

Copy `.env.example` to `.env` and fill in your credentials:

```bash
cp .env.example .env
```

**Important variables to configure:**
- `GOOGLE_API_KEY` - Your Gemini API key
- `ELASTICSEARCH_URL` - Your Elasticsearch endpoint
- `ELASTICSEARCH_API_KEY` - Your Elasticsearch API key
- `MONGODB_URL` - MongoDB connection string

### 3. Start MongoDB

```bash
docker-compose up -d mongodb
```

### 4. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run backend
python -m app.main
```

Backend will run on: `http://localhost:8000`

### 5. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

Frontend will run on: `http://localhost:5173`

## ğŸ“Š Data Ingestion

Load your admissions Q&A data into Elasticsearch:

```bash
cd backend
python scripts/ingest_data.py
```

This will:
1. Read `train.csv`
2. Generate Vietnamese embeddings
3. Index documents to Elasticsearch
4. Create necessary indexes

## ğŸš€ Usage

### Start All Services

```bash
# Terminal 1: Start MongoDB
docker-compose up -d

# Terminal 2: Start Backend
cd backend
python -m app.main

# Terminal 3: Start Frontend
cd frontend
npm run dev
```

### Access Application

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

## ğŸ“ Project Structure

```
Langgragh/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â”œâ”€â”€ database/            # DB connections
â”‚   â”‚   â”‚   â”œâ”€â”€ mongodb.py
â”‚   â”‚   â”‚   â””â”€â”€ elasticsearch.py
â”‚   â”‚   â”œâ”€â”€ models/              # Pydantic models
â”‚   â”‚   â”œâ”€â”€ api/                 # API routes
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ langgraph/           # LangGraph workflows
â”‚   â”‚   â””â”€â”€ utils/               # Utilities
â”‚   â”œâ”€â”€ scripts/                 # Data ingestion scripts
â”‚   â”œâ”€â”€ tests/                   # Unit tests
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ pages/               # Page components
â”‚   â”‚   â”œâ”€â”€ services/            # API services
â”‚   â”‚   â”œâ”€â”€ store/               # State management
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ train.csv                    # Training data
â”œâ”€â”€ docker-compose.yml           # Docker services
â”œâ”€â”€ .env                         # Environment variables
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Elasticsearch Setup

Your Elasticsearch is configured with:
- **URL**: `https://e28a57d7f3774266a59618be9edcc050.us-gov-east-1.aws.elastic-cloud.com:443`
- **Index**: `admissions_qa`
- **Features**: Vietnamese analyzer, vector search, hybrid search

### MongoDB Setup

Collections:
- `users` - User accounts
- `conversations` - Chat history
- `feedback` - User feedback

## ğŸ§ª Testing

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

## ğŸ“ API Endpoints

### Chat
- `POST /api/chat` - Send message
- `GET /api/conversations` - List conversations
- `GET /api/conversations/{id}` - Get conversation

### Authentication
- `POST /api/auth/register` - Register user
- `POST /api/auth/login` - Login
- `POST /api/auth/logout` - Logout

### Admin
- `POST /api/admin/ingest` - Trigger data ingestion
- `GET /api/admin/stats` - Get system statistics

## ğŸ” Security Notes

âš ï¸ **IMPORTANT**: Never commit `.env` file to version control!

Your credentials are configured in `.env`:
- Gemini API key
- Elasticsearch credentials
- JWT secret key

## ğŸ› Troubleshooting

### Elasticsearch Connection Issues
```bash
# Test connection
curl -X GET "https://your-elasticsearch-url:443" \
  -H "Authorization: ApiKey your-api-key"
```

### MongoDB Connection Issues
```bash
# Check if MongoDB is running
docker ps | grep mongodb

# View logs
docker logs admissions_mongodb
```

### Backend Issues
```bash
# Check logs
tail -f backend/logs/app.log

# Verify dependencies
pip list
```

## ğŸ“š Documentation

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangChain Documentation](https://python.langchain.com/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Elasticsearch Documentation](https://www.elastic.co/guide/)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¥ Authors

- Your Name - Initial work

## ğŸ™ Acknowledgments

- LangChain team for amazing tools
- Elastic for search infrastructure
- Google for Gemini API

