# Quick Start Guide

HÆ°á»›ng dáº«n nhanh Ä‘á»ƒ cháº¡y toÃ n bá»™ há»‡ thá»‘ng chatbot tÆ° váº¥n tuyá»ƒn sinh.

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Backend
- Python >= 3.11
- Conda hoáº·c venv
- MongoDB (local hoáº·c cloud)
- Elasticsearch Cloud
- OpenAI API Key

### Frontend
- Node.js >= 18.0.0
- npm >= 9.0.0

## ğŸš€ CÃ i Ä‘áº·t nhanh (5 phÃºt)

### BÆ°á»›c 1: Clone repository

```bash
git clone <repository-url>
cd Langgragh
```

### BÆ°á»›c 2: Setup Backend

```bash
# Táº¡o conda environment
conda create -n LGR python=3.11 -y
conda activate LGR

# CÃ i Ä‘áº·t dependencies
cd backend
pip install -r requirements.txt

# Quay láº¡i root directory
cd ..
```

### BÆ°á»›c 3: Setup Frontend

```bash
cd frontend
npm install
cd ..
```

### BÆ°á»›c 4: Cáº¥u hÃ¬nh Environment Variables

File `.env` Ä‘Ã£ Ä‘Æ°á»£c táº¡o sáºµn á»Ÿ root directory. Kiá»ƒm tra vÃ  cáº­p nháº­t náº¿u cáº§n:

```env
# OpenAI API Key (Báº®T BUá»˜C)
OPENAI_API_KEY=your-api-key-here

# MongoDB (máº·c Ä‘á»‹nh: localhost)
MONGODB_URL=mongodb://localhost:27017

# Elasticsearch Cloud (Ä‘Ã£ cáº¥u hÃ¬nh sáºµn)
ELASTICSEARCH_CLOUD_ID=...
ELASTICSEARCH_API_KEY=...
```

## ğŸ¯ Cháº¡y há»‡ thá»‘ng

### Option 1: Cháº¡y tá»«ng service riÃªng láº»

#### Terminal 1: Backend

```bash
# Tá»« root directory
python run.py --mode single
```

Server backend sáº½ cháº¡y táº¡i: **http://localhost:8000**

#### Terminal 2: Frontend

```bash
cd frontend
npm run dev
```

Frontend sáº½ cháº¡y táº¡i: **http://localhost:3000**

### Option 2: Cháº¡y production vá»›i multi-workers

#### Backend (Production)

```bash
# Auto-calculate optimal workers
python run.py --mode prod

# Hoáº·c custom workers
python run.py --mode prod --workers 4
```

#### Frontend (Production)

```bash
cd frontend
npm run build
npm start
```

## ğŸ§ª Kiá»ƒm tra há»‡ thá»‘ng

### 1. Kiá»ƒm tra Backend Health

```bash
curl http://localhost:8000/api/health
```

Káº¿t quáº£ mong Ä‘á»£i:
```json
{
  "status": "healthy",
  "services": {
    "elasticsearch": { "status": "connected" },
    "mongodb": { "status": "connected" },
    "openai": { "status": "configured" }
  }
}
```

### 2. Test API

```bash
cd backend
python scripts/test_api.py
```

### 3. Test Concurrent Requests

```bash
cd backend
python scripts/test_concurrent.py
```

### 4. Má»Ÿ Frontend

Truy cáº­p: **http://localhost:3000**

Thá»­ há»i:
- "Äiá»u kiá»‡n xÃ©t tuyá»ƒn vÃ o Ä‘áº¡i há»c lÃ  gÃ¬?"
- "Há»c phÃ­ Ä‘áº¡i há»c bao nhiÃªu?"
- "Thá»i gian Ä‘Äƒng kÃ½ xÃ©t tuyá»ƒn khi nÃ o?"

## ğŸ“Š Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                        â”‚
â”‚  - React + TypeScript                                        â”‚
â”‚  - Tailwind CSS                                              â”‚
â”‚  - Zustand (State Management)                                â”‚
â”‚  Port: 3000                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI)                         â”‚
â”‚  - Python 3.11                                               â”‚
â”‚  - LangGraph Workflow                                        â”‚
â”‚  - Multi-worker support                                      â”‚
â”‚  Port: 8000                                                  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚
      â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MongoDB  â”‚  â”‚Elasticsearchâ”‚  â”‚   OpenAI    â”‚
â”‚  Local   â”‚  â”‚   Cloud    â”‚  â”‚ GPT-4o-mini â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Workflow

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Validation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hybrid Search      â”‚
â”‚  (BM25 + Vector)    â”‚
â”‚  Elasticsearch      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reranking          â”‚
â”‚  (Cross-Encoder)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Answer Generation  â”‚
â”‚  (GPT-4o-mini)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Format Output      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
      Response
```

## âš¡ Performance

### Current Performance (GPT-4o-mini)

- **Response Time:** 1.5-2.5 seconds per request
- **Throughput:** 
  - Single worker: ~20 req/min
  - 4 workers: ~80 req/min
  - 8 workers: ~160 req/min
- **Cost:** $0.0008-0.0012 per request

### Bottlenecks

1. **OpenAI API:** 60-70% of total time
2. **Reranking:** 15-25% of total time
3. **Elasticsearch:** 10-15% of total time

## ğŸ› ï¸ Troubleshooting

### Backend khÃ´ng start Ä‘Æ°á»£c

```bash
# Kiá»ƒm tra Python version
python --version  # Pháº£i >= 3.11

# Kiá»ƒm tra dependencies
pip list | grep -E "fastapi|langgraph|openai"

# Reinstall dependencies
pip install -r backend/requirements.txt --force-reinstall
```

### Frontend khÃ´ng start Ä‘Æ°á»£c

```bash
# Kiá»ƒm tra Node version
node --version  # Pháº£i >= 18.0.0

# Clear cache vÃ  reinstall
cd frontend
rm -rf node_modules .next
npm install
```

### MongoDB connection error

```bash
# Kiá»ƒm tra MongoDB cÃ³ Ä‘ang cháº¡y khÃ´ng
# Windows:
net start MongoDB

# Linux/Mac:
sudo systemctl start mongod

# Hoáº·c sá»­ dá»¥ng MongoDB Atlas (cloud)
```

### Elasticsearch connection error

```bash
# Kiá»ƒm tra credentials trong .env
ELASTICSEARCH_CLOUD_ID=...
ELASTICSEARCH_API_KEY=...

# Test connection
curl -X GET "https://your-elasticsearch-url" \
  -H "Authorization: ApiKey your-api-key"
```

### OpenAI API error

```bash
# Kiá»ƒm tra API key
echo $OPENAI_API_KEY

# Test API key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

## ğŸ“š Documentation

- **Backend:** `backend/STRUCTURE.md`
- **Frontend:** `docs/FRONTEND_GUIDE.md`
- **Performance:** `docs/PERFORMANCE_ANALYSIS.md`
- **API:** http://localhost:8000/docs (Swagger UI)

## ğŸ“ Next Steps

1. **Customize UI:** Edit `frontend/src/components/chat/`
2. **Add Features:** Extend `backend/app/api/routes/`
3. **Optimize Performance:** Implement caching (Redis)
4. **Deploy:** Vercel (frontend) + Railway/Render (backend)

## ğŸ’¡ Tips

- **Development:** Use `--mode single` for easier debugging
- **Production:** Use `--mode prod` for better performance
- **Testing:** Run `test_concurrent.py` to verify multi-user support
- **Monitoring:** Check logs in `backend/logs/`

## ğŸ†˜ Support

Náº¿u gáº·p váº¥n Ä‘á», kiá»ƒm tra:
1. Logs: `backend/logs/app.log`
2. Browser console (F12)
3. Network tab (F12 â†’ Network)
4. Backend terminal output

## ğŸ‰ Success!

Náº¿u má»i thá»© hoáº¡t Ä‘á»™ng:
- âœ… Backend: http://localhost:8000/docs
- âœ… Frontend: http://localhost:3000
- âœ… Health check: http://localhost:8000/api/health

Báº¡n Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng chatbot! ğŸš€

